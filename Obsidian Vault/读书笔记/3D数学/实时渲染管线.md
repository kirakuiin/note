---
special_tag: 3D  Math
tags:
  - reference
---
假如我们拥有无限的算力，那么[[渲染原理#渲染方程]]可以正确的反应现实世界中的光照。但我们没有这样的算力，所以我们必须要了解渲染中的权衡。

下面描述了实时渲染管线的流程，这并不是唯一的管线，但其中许多原理是放之四海而皆准的。

1. 设置场景。比如说放置被渲染的物体，设置光源，放置相机等等。
2. 确定哪些物体对相机来说可见。因为性能很宝贵，所以在渲染前排除看不见的物体。
3. 设置对象级的渲染状态。比如每个对象的纹理，材质，法线等等。
4. 几何数据提交。将需要被渲染的几何体数据提交到渲染API，提交的形式可能是多样的，比如三角形，索引三角形等等。
5. 顶点操作。渲染API会将坐标变换到相机空间，可能还包含纹理坐标生成，蒙皮等操作，这一过程会在顶点着色器的脚本中完成。
6. 剔除，裁剪和投影。为了将3D空间中的三角形投射到2D屏幕上，应该进行下列步骤：
	- 三角形超出视锥体的部分范围要被裁剪。可能会将其变为一个多边形。
	- 将面向近似摄像机观察方向的三角形全部剔除，因为它们的面对相机来说是不可见的。
	- 将三角形用投影矩阵变换到2D的标准设备坐标上。
7. 光栅化。光栅化可以简单理解为将三角形的位置映射到屏幕的像素上，对每个像素的纹理坐标，颜色，光照等进行插值，并将结果传递至下一阶段。
8. 像素着色。为像素计算一个颜色的过程叫做着色，这是计算机图形学的核心，一旦算好之后就会将其颜色和深度写入缓冲区。这一过程一般是由像素着色器脚本完成的。
9. 混合和输出。在管线的最后我们得到了一个像素的颜色，深度和透明度，如果它的深度小于缓冲里的深度并且是部分透明的，那么这个颜色就会和缓冲区里的颜色按照某些透明度公式混合成新的颜色，这一过程叫做$alpha$混合。

```python
setup_camera()

clear_z_buffer()

for obj in obj_list:
	if not is_visible_for_camera(obj):
		continue

	all_meshs = obj.get_geometry()

	for triangle in all_meshs:

		// 顶点级操作
		tri = vertex_shade(triangle)

		// 裁剪超出视锥体部分
		clipped_tri = clip_to_view(tri)

		// 变换到屏幕空间
		screen_tri = project_to_screen(clipped_tri)

		if is_back_facing(screen_tri):
			continue

		// 光栅化
		rasterization()

		for pixel in triangle:
			color = pixel_shade()

			if not z_buffer_test():
				continue

			if not alpha_test():
				continue
			
			write_pixel(color, z)	
		
```

用数据流上来说：
![[graphics_pipeline_data_flow.png]]

从操作层次来说：
![[graphics_pipeline_division_of_labor.png]]

# 缓冲区