---
special_tag: 3D  Math
tags:
  - reference
---
假如我们拥有无限的算力，那么[[渲染原理#渲染方程|渲染方程]]可以正确的反应现实世界中的光照。但我们没有这样的算力，所以我们必须要了解渲染中的权衡。

下面描述了实时渲染管线的流程，这并不是唯一的管线，但其中许多原理是放之四海而皆准的。

1. 设置场景。比如说放置被渲染的物体，设置光源，放置相机等等。
2. 确定哪些物体对相机来说可见。因为性能很宝贵，所以在渲染前排除看不见的物体。
3. 设置对象级的渲染状态。比如每个对象的纹理，材质，法线等等。
4. [[实时渲染管线#几何数据提交|几何数据提交]]。将需要被渲染的几何体数据提交到渲染API，提交的形式可能是多样的，比如三角形，索引三角形等等。
5. 顶点操作。渲染API会将坐标变换到相机空间，可能还包含纹理坐标生成，蒙皮等操作，这一过程会在顶点着色器的脚本中完成。
6. [[实时渲染管线#背面剔除|剔除]]，[[实时渲染管线#裁剪|裁剪]]和[[3D空间变换#准备投影|投影]]。为了将3D空间中的三角形投射到2D屏幕上，应该进行下列步骤：
	- 三角形超出视锥体的部分范围要被裁剪。可能会将其变为一个多边形。
	- 将面向近似摄像机观察方向的三角形全部剔除，因为它们的面对相机来说是不可见的。
	- 将三角形用投影矩阵变换到2D的标准设备坐标上。
7. [[实时渲染管线#光栅化|光栅化]]。光栅化可以简单理解为将三角形的位置映射到屏幕的像素上，对每个像素的纹理坐标，颜色，光照等进行插值，并将结果传递至下一阶段。
8. 像素着色。为像素计算一个颜色的过程叫做着色，这是计算机图形学的核心，一旦算好之后就会将其颜色和深度写入[[实时渲染管线#缓冲区|缓冲区]]。这一过程一般是由像素着色器脚本完成的。
9. 混合和输出。在管线的最后我们得到了一个像素的颜色，深度和透明度，如果它的深度小于缓冲里的深度并且是部分透明的，那么这个颜色就会和缓冲区里的颜色按照某些透明度公式混合成新的颜色，这一过程叫做$alpha$混合。

```python
setup_camera()

clear_z_buffer()

for obj in obj_list:
	if not is_visible_for_camera(obj):
		continue

	all_meshs = obj.get_geometry()

	for triangle in all_meshs:

		// 顶点级操作
		tri = vertex_shade(triangle)

		// 裁剪超出视锥体部分
		clipped_tri = clip_to_view(tri)

		// 变换到屏幕空间
		screen_tri = project_to_screen(clipped_tri)

		if is_back_facing(screen_tri):
			continue

		// 光栅化
		rasterization()

		for pixel in triangle:
			color = pixel_shade()

			if not z_buffer_test():
				continue

			if not alpha_test():
				continue
			
			write_pixel(color, z)	
		
```

用数据流上来说：
![[graphics_pipeline_data_flow.png]]

从操作层次来说：
![[graphics_pipeline_division_of_labor.png]]

# 缓冲区

所谓的缓冲区，指的就是内存中用来存储数据的一段连续的区域，其中最重要的就是颜色缓冲和深度缓冲。

颜色缓冲内部存储着每个像素的颜色，显卡会不断读取其中的内容来更新屏幕上的显示。为了防止边读取边修改的情况发生，引入了[[双缓冲]]技术。

深度缓冲是用来辅助决定某个计算出来的颜色是否应该被渲染的。如果新颜色的深度较高，证明它会被之前的像素遮住，此时这个颜色就会被丢弃。而已经渲染好的图像是不再需要深度缓冲的，所以这个使用一个缓冲就够了。

# 几何数据提交

这一步需要将一些渲染需要用到的数据提交到API中，比如：
- 位置：顶点的模型空间的位置，后面需要变换到裁剪空间。
- 纹理信息：顶点对应的纹理坐标，使用的纹理等等。
- 表面法线：光照需要使用法线来计算。
- 切空间：法线表示法所位于的空间。

# 顶点操作

在基于着色器的流程中，它的输入就是上一节里提到的那些信息，输出可以有很多，但必须输出两种信息：
- 裁剪空间坐标。
- 像素着色器所需要的信息。

一些最常见的操作是：
- 模型空间转为裁剪空间 。
- 骨骼蒙皮。
- 将法线转换到适当的空间。
- 计算照明所需要的矢量$\textbf{l}$，$\textbf{h}$。
- 程序性生成纹理坐标。

# 裁剪和剔除

当顶点转化到裁剪空间后，需要对三角形做两个重要的测试：

## 裁剪

这一过程通常由API自动执行，其原理为将一个多边形的每个边依次和裁剪平面进行测试，输出0到2个顶点。

![[clip_rules.png]]

上图描述了对于不同情况的边的输出情况。然后对每个多边形的每条边进行这样的测试，最后将结果汇总，流程如下：

![[clip_example.png]]

用了4步对多边形完成了裁剪，将平面以外的部分去除，并构成了一个新的多边形。

## 背面剔除

该测试的目的是丢弃不面向相机的面，尽管在不透明的场景下，这种面也无法通过深度测试，但不渲染是最佳的优化方式。在实际的场景里有一半不到的面会被剔除。

硬件渲染里，其原理就是检测三角形在坐标空间中是顺时针的还是逆时针排列的，比如左手系中，顺时针就是正面，所以所有的逆时针面都会被剔除。

![[backface_culling_vertex_order.png]]

对于软件渲染来说，通常采用的方式为计算三角形表面法线，然后相机到三角形的向量对比，如果它们的夹角位于$(0\degree, 90\degree)$，那么就会被剔除。

![[backface_culling.png]]

# 光栅化

裁剪后，根据[[3D空间变换#屏幕空间|屏幕空间]]里的公式将器变换到屏幕空间。但这些坐标是连续的，而像素是离散的。我们如何知道哪些像素需要被绘制呢？图形硬件解决了这个问题，我们不再需要为此而烦恼。

因此我们不需要关系如何确定三角形哪些部分被渲染，这部分由硬件处理，但对于每个像素我们还是要了解处理的细节：
1. 插值：任何像素着色前，其顶点级的计算都需要在表面上插值。
2. 深度测试：通过深度缓冲来丢弃哪些距离我们较远的像素。
3. 透明度测试：如果像素透明度过高，也会被丢弃。此时不会更新深度缓冲区。
4. 更新：新深度替换旧深度，新的颜色和旧的颜色混合，再将其颜色写到缓冲区。